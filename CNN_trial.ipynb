{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my first attempt at building a CNN inspired by the LeNet architecture. The Lenet architecture consists of two sets of convolutional and pooling layers, followed by two fully connected layers. Let's get to building!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get to building, we need to generate data. So far, I have generated data from the following datasets:\n",
    "* i3c3a1d0v5a0_set18a\n",
    "* i3c3a1d0v5a0_set18b\n",
    "* i3c3a1d0v5a0_set18d\n",
    "* i3c3a1d0v5a2_set21\n",
    "* i3c3a1d0v5a7_set21\n",
    "* i3c3a1d0v5a14_set21\n",
    "* i3c3a1d0v5a15_set21\n",
    "* i3c3a1d1v5a0_set22\n",
    "* i3c3a1d1v5a7_set22\n",
    "* i3c4a1d0v5a0_set20\n",
    "* i3c4a1d0v5a0_set23\n",
    "* i3c5a1d0v5a0_set20\n",
    "* i3c5a1d0v5a0_set23\n",
    "* i3c3a0d0v5a2_set17 - bad data set, ignore\n",
    "* i3c3a0d1v5a2_set17 - also bad data set, ignore \n",
    "The two last datasets are deemed as \"bad\" because they did not have any T1 transitions. I suspect that something was weird with the data generation process from the master code, but I am not sure. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, import the necessary libraries. These ones are pretty standard, courtesy of Harish's notebook for generating the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from phasefield_scripts.load_files import *\n",
    "# from phasefield_scripts.procedures import *\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widget\n",
    "from ipywidgets import fixed\n",
    "import os\n",
    "import pickle\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "%matplotlib widget\n",
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Torch libraries to make building the CNN a lot easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nigar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\Nigar\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "# from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, time to import your dataset. Harish has already generated the dataset for me - both the images and numpy arrays. I will be importing the arrays directly, to then turn them into tensors using PyTorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "[[False False  True ... False False False]\n",
      " [False False  True ... False False False]\n",
      " [False False  True ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "(40, 40)\n"
     ]
    }
   ],
   "source": [
    "#train and test data directory\n",
    "expname_train = 'i3c3a1d0v5a0_set18a'\n",
    "expname_test = 'i3c3a1d0v5a0_set18b'\n",
    "\n",
    "input_train_dir = 'data\\\\' + expname_train\n",
    "data_train_dir = input_train_dir + '/images'\n",
    "\n",
    "input_test_dir = 'data\\\\' + expname_test\n",
    "data_test_dir = input_test_dir + '/images'\n",
    "\n",
    "length_tissue = len([name for name in os.listdir(data_train_dir) if name.startswith('tissue')])\n",
    "print(length_tissue)\n",
    "\n",
    "\n",
    "test = np.load(data_train_dir + '\\\\tissue00000.npy')\n",
    "print(test)\n",
    "print(test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here, I have noticed that it is not as trivial to make an array of arrays... So I tried importing images instead of the arrays in hopes of making my life easiert, but it did not really help - ImageFolder from PyTorch wants me to sort my images into folders (while also implementing classes for T1 == yes and T1 == no), which I have not done yet. In order to sort my files the way PyTorch wants me to, I will use my T1-transition arrays and make the correct folders. But this is something for future Nigar to worry about tomorrow... :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Couldn't find any class folder in data\\i3c3a1d0v5a0_set18a/images.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\t1\\CNN_trial.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/t1/CNN_trial.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/t1/CNN_trial.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     transforms\u001b[39m.\u001b[39mResize((\u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m)),\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/t1/CNN_trial.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     transforms\u001b[39m.\u001b[39mToTensor(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/t1/CNN_trial.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     transforms\u001b[39m.\u001b[39mNormalize(mean\u001b[39m=\u001b[39m[\u001b[39m0.485\u001b[39m, \u001b[39m0.456\u001b[39m, \u001b[39m0.406\u001b[39m], \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/t1/CNN_trial.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                          std\u001b[39m=\u001b[39m[\u001b[39m0.229\u001b[39m, \u001b[39m0.224\u001b[39m, \u001b[39m0.225\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/t1/CNN_trial.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m ])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/t1/CNN_trial.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# create a dataset object using the ImageFolder class\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/t1/CNN_trial.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m dataset \u001b[39m=\u001b[39m ImageFolder(root\u001b[39m=\u001b[39;49mdata_dir, transform\u001b[39m=\u001b[39;49mtransform)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/t1/CNN_trial.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# create a dataloader object using the DataLoader class\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/t1/CNN_trial.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoader(dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Nigar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\folder.py:310\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    303\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    304\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    308\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m ):\n\u001b[1;32m--> 310\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m    311\u001b[0m         root,\n\u001b[0;32m    312\u001b[0m         loader,\n\u001b[0;32m    313\u001b[0m         IMG_EXTENSIONS \u001b[39mif\u001b[39;49;00m is_valid_file \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    314\u001b[0m         transform\u001b[39m=\u001b[39;49mtransform,\n\u001b[0;32m    315\u001b[0m         target_transform\u001b[39m=\u001b[39;49mtarget_transform,\n\u001b[0;32m    316\u001b[0m         is_valid_file\u001b[39m=\u001b[39;49mis_valid_file,\n\u001b[0;32m    317\u001b[0m     )\n\u001b[0;32m    318\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msamples\n",
      "File \u001b[1;32mc:\\Users\\Nigar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\folder.py:145\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    136\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    137\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    142\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    143\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(root, transform\u001b[39m=\u001b[39mtransform, target_transform\u001b[39m=\u001b[39mtarget_transform)\n\u001b[1;32m--> 145\u001b[0m     classes, class_to_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_classes(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot)\n\u001b[0;32m    146\u001b[0m     samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_dataset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[0;32m    148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader \u001b[39m=\u001b[39m loader\n",
      "File \u001b[1;32mc:\\Users\\Nigar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\folder.py:219\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_classes\u001b[39m(\u001b[39mself\u001b[39m, directory: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[\u001b[39mstr\u001b[39m], Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m]]:\n\u001b[0;32m    193\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m \u001b[39m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[39m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 219\u001b[0m     \u001b[39mreturn\u001b[39;00m find_classes(directory)\n",
      "File \u001b[1;32mc:\\Users\\Nigar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\folder.py:43\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     41\u001b[0m classes \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(entry\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mscandir(directory) \u001b[39mif\u001b[39;00m entry\u001b[39m.\u001b[39mis_dir())\n\u001b[0;32m     42\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[1;32m---> 43\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find any class folder in \u001b[39m\u001b[39m{\u001b[39;00mdirectory\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m class_to_idx \u001b[39m=\u001b[39m {cls_name: i \u001b[39mfor\u001b[39;00m i, cls_name \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(classes)}\n\u001b[0;32m     46\u001b[0m \u001b[39mreturn\u001b[39;00m classes, class_to_idx\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Couldn't find any class folder in data\\i3c3a1d0v5a0_set18a/images."
     ]
    }
   ],
   "source": [
    "# images = data_train_dir + '/img'\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# define the path to the directory containing the image data\n",
    "data_dir = data_train_dir\n",
    "\n",
    "# define the image transformations to be applied to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# create a dataset object using the ImageFolder class\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# create a dataloader object using the DataLoader class\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# iterate over the batches of images\n",
    "for images, labels in dataloader:\n",
    "    # do something with the images and labels\n",
    "    print(images.shape, labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "def data_loader(data_dir):\n",
    "    tissue_train = []\n",
    "    tissue_files = [file_name for file_name in os.listdir(data_dir) if file_name.startswith('tissue')]\n",
    "    for file_name in tissue_files:\n",
    "        tissue_train.append(file_name)\n",
    "    data = np.array(tissue_train)\n",
    "    return data\n",
    "\n",
    "train_data = data_loader(data_train_dir)\n",
    "test_data = data_loader(data_test_dir)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small piece of code for counting T1 transitions in training set + test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#open the T1 locations numpy file from images folder \n",
    "T1_labels_test = np.load(data_train_dir + '\\\\T1_status.npy') #18\n",
    "T1_labels_train = np.load(data_test_dir + '\\\\T1_status.npy')\n",
    "\n",
    "print(T1_labels_test)\n",
    "print(T1_labels_train)\n",
    "\n",
    "#function for counting the number of 1's in T1_status, sanity check \n",
    "def T1_true(T1_labels):\n",
    "    T1_true = np.count_nonzero(T1_labels)\n",
    "    return T1_true\n",
    "\n",
    "print(T1_true(T1_labels_train))\n",
    "print(T1_true(T1_labels_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I was trying to reshape my arrays but it went terribly wrong..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 50 into shape (50,1,150,150)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\t1\\CNN_trial.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/t1/CNN_trial.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# data_dir = \"../input/intel-image-classification/seg_train/seg_train/\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/t1/CNN_trial.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# test_data_dir = \"../input/intel-image-classification/seg_test/seg_test\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/t1/CNN_trial.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/t1/CNN_trial.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# ]))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/t1/CNN_trial.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m#reshape the data to be 4D tensor\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/t1/CNN_trial.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m train_data \u001b[39m=\u001b[39m train_data\u001b[39m.\u001b[39;49mreshape(length_tissue, \u001b[39m1\u001b[39;49m, \u001b[39m150\u001b[39;49m, \u001b[39m150\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/t1/CNN_trial.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m test_data \u001b[39m=\u001b[39m test_data\u001b[39m.\u001b[39mreshape(length_tissue, \u001b[39m1\u001b[39m, \u001b[39m150\u001b[39m, \u001b[39m150\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 50 into shape (50,1,150,150)"
     ]
    }
   ],
   "source": [
    "\n",
    "#reshape the data to be 4D tensor\n",
    "#this approach does not work!!!!\n",
    "train_data = train_data.reshape(length_tissue, 1, 150, 150)\n",
    "test_data = test_data.reshape(length_tissue, 1, 150, 150)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, most of the code above can be ignored. Tomorrow's Nigar has to find a way to sort her data into proper folders so that ImageFolder can be used. To do this, she will need to use T1_labels arrays for each experiment. Good luck :) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
