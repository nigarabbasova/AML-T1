{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nigar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\Nigar\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "# from phasefield_scripts.load_files import *\n",
    "# from phasefield_scripts.procedures import *\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "# import ipywidgets as widget\n",
    "# from ipywidgets import fixed\n",
    "import os\n",
    "import pickle\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "# %matplotlib widget\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in train set: 593\n",
      "Number of samples in validation set: 149\n",
      "Number of samples in test set: 672\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# define the path to the data directory\n",
    "data_dir = 'data_CNN_20,50_ready\\\\'\n",
    "\n",
    "test_data_dir = 'test_data_CNN_ready\\\\'\n",
    "\n",
    "\n",
    "# define the transformations to be applied to the images\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((224, 224)),  #this will resize images to 224x224 but I am not sure if this is necessary\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# create the ImageFolder dataset\n",
    "dataset = ImageFolder(data_dir, transform=transform) #subdirectories are the classes: T0 = 0 and T1 = 1\n",
    "test_dataset = ImageFolder(test_data_dir, transform=transform)\n",
    "# print(dataset.classes)\n",
    "\n",
    "\n",
    "# split the dataset into train and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# create the data loaders for the train and validation sets\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size) #shuffle = False here, this is apparently better for validation data \n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# print the number of samples in the train and validation sets\n",
    "print(f\"Number of samples in train set: {len(train_dataset)}\")\n",
    "print(f\"Number of samples in validation set: {len(val_dataset)}\")\n",
    "print(f\"Number of samples in test set: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.686\n",
      "[1,     2] loss: 0.712\n",
      "[1,     3] loss: 0.729\n",
      "[1,     4] loss: 0.717\n",
      "[1,     5] loss: 0.708\n",
      "[1,     6] loss: 0.706\n",
      "[1,     7] loss: 0.710\n",
      "[1,     8] loss: 0.703\n",
      "[1,     9] loss: 0.700\n",
      "[1,    10] loss: 0.700\n",
      "[1,    11] loss: 0.700\n",
      "[1,    12] loss: 0.695\n",
      "[1,    13] loss: 0.698\n",
      "[1,    14] loss: 0.696\n",
      "[1,    15] loss: 0.692\n",
      "[1,    16] loss: 0.688\n",
      "[1,    17] loss: 0.689\n",
      "[1,    18] loss: 0.687\n",
      "[1,    19] loss: 0.687\n",
      "[1,    20] loss: 0.691\n",
      "[1,    21] loss: 0.692\n",
      "[1,    22] loss: 0.689\n",
      "[1,    23] loss: 0.686\n",
      "[1,    24] loss: 0.685\n",
      "[1,    25] loss: 0.686\n",
      "[1,    26] loss: 0.685\n",
      "[1,    27] loss: 0.683\n",
      "[1,    28] loss: 0.682\n",
      "[1,    29] loss: 0.680\n",
      "[1,    30] loss: 0.678\n",
      "[1,    31] loss: 0.676\n",
      "[1,    32] loss: 0.675\n",
      "[1,    33] loss: 0.673\n",
      "[1,    34] loss: 0.670\n",
      "[1,    35] loss: 0.667\n",
      "[1,    36] loss: 0.667\n",
      "[1,    37] loss: 0.667\n",
      "[1,    38] loss: 0.659\n",
      "[2,     1] loss: 0.674\n",
      "[2,     2] loss: 0.607\n",
      "[2,     3] loss: 0.587\n",
      "[2,     4] loss: 0.568\n",
      "[2,     5] loss: 0.574\n",
      "[2,     6] loss: 0.566\n",
      "[2,     7] loss: 0.551\n",
      "[2,     8] loss: 0.535\n",
      "[2,     9] loss: 0.529\n",
      "[2,    10] loss: 0.526\n",
      "[2,    11] loss: 0.523\n",
      "[2,    12] loss: 0.513\n",
      "[2,    13] loss: 0.499\n",
      "[2,    14] loss: 0.491\n",
      "[2,    15] loss: 0.486\n",
      "[2,    16] loss: 0.484\n",
      "[2,    17] loss: 0.490\n",
      "[2,    18] loss: 0.482\n",
      "[2,    19] loss: 0.498\n",
      "[2,    20] loss: 0.498\n",
      "[2,    21] loss: 0.515\n",
      "[2,    22] loss: 0.507\n",
      "[2,    23] loss: 0.504\n",
      "[2,    24] loss: 0.493\n",
      "[2,    25] loss: 0.488\n",
      "[2,    26] loss: 0.493\n",
      "[2,    27] loss: 0.493\n",
      "[2,    28] loss: 0.488\n",
      "[2,    29] loss: 0.487\n",
      "[2,    30] loss: 0.488\n",
      "[2,    31] loss: 0.495\n",
      "[2,    32] loss: 0.490\n",
      "[2,    33] loss: 0.485\n",
      "[2,    34] loss: 0.481\n",
      "[2,    35] loss: 0.481\n",
      "[2,    36] loss: 0.479\n",
      "[2,    37] loss: 0.476\n",
      "[2,    38] loss: 0.466\n",
      "[3,     1] loss: 0.409\n",
      "[3,     2] loss: 0.318\n",
      "[3,     3] loss: 0.281\n",
      "[3,     4] loss: 0.314\n",
      "[3,     5] loss: 0.287\n",
      "[3,     6] loss: 0.277\n",
      "[3,     7] loss: 0.261\n",
      "[3,     8] loss: 0.257\n",
      "[3,     9] loss: 0.253\n",
      "[3,    10] loss: 0.250\n",
      "[3,    11] loss: 0.240\n",
      "[3,    12] loss: 0.244\n",
      "[3,    13] loss: 0.247\n",
      "[3,    14] loss: 0.244\n",
      "[3,    15] loss: 0.238\n",
      "[3,    16] loss: 0.245\n",
      "[3,    17] loss: 0.239\n",
      "[3,    18] loss: 0.240\n",
      "[3,    19] loss: 0.236\n",
      "[3,    20] loss: 0.226\n",
      "[3,    21] loss: 0.220\n",
      "[3,    22] loss: 0.215\n",
      "[3,    23] loss: 0.214\n",
      "[3,    24] loss: 0.211\n",
      "[3,    25] loss: 0.217\n",
      "[3,    26] loss: 0.214\n",
      "[3,    27] loss: 0.209\n",
      "[3,    28] loss: 0.207\n",
      "[3,    29] loss: 0.213\n",
      "[3,    30] loss: 0.214\n",
      "[3,    31] loss: 0.226\n",
      "[3,    32] loss: 0.220\n",
      "[3,    33] loss: 0.223\n",
      "[3,    34] loss: 0.228\n",
      "[3,    35] loss: 0.227\n",
      "[3,    36] loss: 0.223\n",
      "[3,    37] loss: 0.222\n",
      "[3,    38] loss: 0.217\n",
      "[4,     1] loss: 0.068\n",
      "[4,     2] loss: 0.081\n",
      "[4,     3] loss: 0.074\n",
      "[4,     4] loss: 0.086\n",
      "[4,     5] loss: 0.111\n",
      "[4,     6] loss: 0.112\n",
      "[4,     7] loss: 0.113\n",
      "[4,     8] loss: 0.128\n",
      "[4,     9] loss: 0.124\n",
      "[4,    10] loss: 0.119\n",
      "[4,    11] loss: 0.114\n",
      "[4,    12] loss: 0.107\n",
      "[4,    13] loss: 0.104\n",
      "[4,    14] loss: 0.102\n",
      "[4,    15] loss: 0.117\n",
      "[4,    16] loss: 0.118\n",
      "[4,    17] loss: 0.113\n",
      "[4,    18] loss: 0.115\n",
      "[4,    19] loss: 0.116\n",
      "[4,    20] loss: 0.112\n",
      "[4,    21] loss: 0.110\n",
      "[4,    22] loss: 0.110\n",
      "[4,    23] loss: 0.107\n",
      "[4,    24] loss: 0.107\n",
      "[4,    25] loss: 0.107\n",
      "[4,    26] loss: 0.105\n",
      "[4,    27] loss: 0.104\n",
      "[4,    28] loss: 0.103\n",
      "[4,    29] loss: 0.102\n",
      "[4,    30] loss: 0.100\n",
      "[4,    31] loss: 0.097\n",
      "[4,    32] loss: 0.095\n",
      "[4,    33] loss: 0.094\n",
      "[4,    34] loss: 0.093\n",
      "[4,    35] loss: 0.091\n",
      "[4,    36] loss: 0.092\n",
      "[4,    37] loss: 0.093\n",
      "[4,    38] loss: 0.090\n",
      "[5,     1] loss: 0.016\n",
      "[5,     2] loss: 0.035\n",
      "[5,     3] loss: 0.062\n",
      "[5,     4] loss: 0.050\n",
      "[5,     5] loss: 0.046\n",
      "[5,     6] loss: 0.040\n",
      "[5,     7] loss: 0.035\n",
      "[5,     8] loss: 0.032\n",
      "[5,     9] loss: 0.029\n",
      "[5,    10] loss: 0.027\n",
      "[5,    11] loss: 0.028\n",
      "[5,    12] loss: 0.027\n",
      "[5,    13] loss: 0.025\n",
      "[5,    14] loss: 0.024\n",
      "[5,    15] loss: 0.034\n",
      "[5,    16] loss: 0.032\n",
      "[5,    17] loss: 0.031\n",
      "[5,    18] loss: 0.031\n",
      "[5,    19] loss: 0.049\n",
      "[5,    20] loss: 0.056\n",
      "[5,    21] loss: 0.061\n",
      "[5,    22] loss: 0.059\n",
      "[5,    23] loss: 0.063\n",
      "[5,    24] loss: 0.062\n",
      "[5,    25] loss: 0.060\n",
      "[5,    26] loss: 0.061\n",
      "[5,    27] loss: 0.065\n",
      "[5,    28] loss: 0.067\n",
      "[5,    29] loss: 0.065\n",
      "[5,    30] loss: 0.066\n",
      "[5,    31] loss: 0.066\n",
      "[5,    32] loss: 0.065\n",
      "[5,    33] loss: 0.063\n",
      "[5,    34] loss: 0.063\n",
      "[5,    35] loss: 0.062\n",
      "[5,    36] loss: 0.062\n",
      "[5,    37] loss: 0.060\n",
      "[5,    38] loss: 0.065\n",
      "[6,     1] loss: 0.091\n",
      "[6,     2] loss: 0.341\n",
      "[6,     3] loss: 0.255\n",
      "[6,     4] loss: 0.315\n",
      "[6,     5] loss: 0.252\n",
      "[6,     6] loss: 0.215\n",
      "[6,     7] loss: 0.225\n",
      "[6,     8] loss: 0.198\n",
      "[6,     9] loss: 0.202\n",
      "[6,    10] loss: 0.182\n",
      "[6,    11] loss: 0.178\n",
      "[6,    12] loss: 0.169\n",
      "[6,    13] loss: 0.158\n",
      "[6,    14] loss: 0.150\n",
      "[6,    15] loss: 0.142\n",
      "[6,    16] loss: 0.167\n",
      "[6,    17] loss: 0.171\n",
      "[6,    18] loss: 0.165\n",
      "[6,    19] loss: 0.157\n",
      "[6,    20] loss: 0.158\n",
      "[6,    21] loss: 0.156\n",
      "[6,    22] loss: 0.152\n",
      "[6,    23] loss: 0.148\n",
      "[6,    24] loss: 0.144\n",
      "[6,    25] loss: 0.148\n",
      "[6,    26] loss: 0.144\n",
      "[6,    27] loss: 0.140\n",
      "[6,    28] loss: 0.136\n",
      "[6,    29] loss: 0.132\n",
      "[6,    30] loss: 0.128\n",
      "[6,    31] loss: 0.125\n",
      "[6,    32] loss: 0.121\n",
      "[6,    33] loss: 0.119\n",
      "[6,    34] loss: 0.115\n",
      "[6,    35] loss: 0.112\n",
      "[6,    36] loss: 0.111\n",
      "[6,    37] loss: 0.109\n",
      "[6,    38] loss: 0.107\n",
      "[7,     1] loss: 0.010\n",
      "[7,     2] loss: 0.008\n",
      "[7,     3] loss: 0.009\n",
      "[7,     4] loss: 0.012\n",
      "[7,     5] loss: 0.013\n",
      "[7,     6] loss: 0.053\n",
      "[7,     7] loss: 0.047\n",
      "[7,     8] loss: 0.052\n",
      "[7,     9] loss: 0.047\n",
      "[7,    10] loss: 0.045\n",
      "[7,    11] loss: 0.045\n",
      "[7,    12] loss: 0.043\n",
      "[7,    13] loss: 0.042\n",
      "[7,    14] loss: 0.050\n",
      "[7,    15] loss: 0.048\n",
      "[7,    16] loss: 0.045\n",
      "[7,    17] loss: 0.043\n",
      "[7,    18] loss: 0.041\n",
      "[7,    19] loss: 0.042\n",
      "[7,    20] loss: 0.042\n",
      "[7,    21] loss: 0.041\n",
      "[7,    22] loss: 0.054\n",
      "[7,    23] loss: 0.052\n",
      "[7,    24] loss: 0.050\n",
      "[7,    25] loss: 0.048\n",
      "[7,    26] loss: 0.047\n",
      "[7,    27] loss: 0.046\n",
      "[7,    28] loss: 0.048\n",
      "[7,    29] loss: 0.052\n",
      "[7,    30] loss: 0.053\n",
      "[7,    31] loss: 0.051\n",
      "[7,    32] loss: 0.050\n",
      "[7,    33] loss: 0.049\n",
      "[7,    34] loss: 0.048\n",
      "[7,    35] loss: 0.046\n",
      "[7,    36] loss: 0.047\n",
      "[7,    37] loss: 0.048\n",
      "[7,    38] loss: 0.047\n",
      "[8,     1] loss: 0.010\n",
      "[8,     2] loss: 0.007\n",
      "[8,     3] loss: 0.042\n",
      "[8,     4] loss: 0.035\n",
      "[8,     5] loss: 0.036\n",
      "[8,     6] loss: 0.031\n",
      "[8,     7] loss: 0.028\n",
      "[8,     8] loss: 0.025\n",
      "[8,     9] loss: 0.043\n",
      "[8,    10] loss: 0.041\n",
      "[8,    11] loss: 0.038\n",
      "[8,    12] loss: 0.036\n",
      "[8,    13] loss: 0.036\n",
      "[8,    14] loss: 0.035\n",
      "[8,    15] loss: 0.033\n",
      "[8,    16] loss: 0.032\n",
      "[8,    17] loss: 0.032\n",
      "[8,    18] loss: 0.030\n",
      "[8,    19] loss: 0.029\n",
      "[8,    20] loss: 0.034\n",
      "[8,    21] loss: 0.033\n",
      "[8,    22] loss: 0.033\n",
      "[8,    23] loss: 0.031\n",
      "[8,    24] loss: 0.030\n",
      "[8,    25] loss: 0.029\n",
      "[8,    26] loss: 0.029\n",
      "[8,    27] loss: 0.028\n",
      "[8,    28] loss: 0.028\n",
      "[8,    29] loss: 0.027\n",
      "[8,    30] loss: 0.027\n",
      "[8,    31] loss: 0.027\n",
      "[8,    32] loss: 0.026\n",
      "[8,    33] loss: 0.026\n",
      "[8,    34] loss: 0.025\n",
      "[8,    35] loss: 0.024\n",
      "[8,    36] loss: 0.024\n",
      "[8,    37] loss: 0.023\n",
      "[8,    38] loss: 0.023\n",
      "[9,     1] loss: 0.056\n",
      "[9,     2] loss: 0.030\n",
      "[9,     3] loss: 0.032\n",
      "[9,     4] loss: 0.025\n",
      "[9,     5] loss: 0.023\n",
      "[9,     6] loss: 0.021\n",
      "[9,     7] loss: 0.044\n",
      "[9,     8] loss: 0.051\n",
      "[9,     9] loss: 0.047\n",
      "[9,    10] loss: 0.043\n",
      "[9,    11] loss: 0.040\n",
      "[9,    12] loss: 0.037\n",
      "[9,    13] loss: 0.036\n",
      "[9,    14] loss: 0.035\n",
      "[9,    15] loss: 0.042\n",
      "[9,    16] loss: 0.040\n",
      "[9,    17] loss: 0.042\n",
      "[9,    18] loss: 0.040\n",
      "[9,    19] loss: 0.038\n",
      "[9,    20] loss: 0.036\n",
      "[9,    21] loss: 0.054\n",
      "[9,    22] loss: 0.057\n",
      "[9,    23] loss: 0.055\n",
      "[9,    24] loss: 0.053\n",
      "[9,    25] loss: 0.051\n",
      "[9,    26] loss: 0.049\n",
      "[9,    27] loss: 0.049\n",
      "[9,    28] loss: 0.048\n",
      "[9,    29] loss: 0.049\n",
      "[9,    30] loss: 0.047\n",
      "[9,    31] loss: 0.046\n",
      "[9,    32] loss: 0.045\n",
      "[9,    33] loss: 0.044\n",
      "[9,    34] loss: 0.051\n",
      "[9,    35] loss: 0.050\n",
      "[9,    36] loss: 0.049\n",
      "[9,    37] loss: 0.048\n",
      "[9,    38] loss: 0.049\n",
      "[10,     1] loss: 0.021\n",
      "[10,     2] loss: 0.062\n",
      "[10,     3] loss: 0.073\n",
      "[10,     4] loss: 0.060\n",
      "[10,     5] loss: 0.065\n",
      "[10,     6] loss: 0.095\n",
      "[10,     7] loss: 0.084\n",
      "[10,     8] loss: 0.075\n",
      "[10,     9] loss: 0.069\n",
      "[10,    10] loss: 0.064\n",
      "[10,    11] loss: 0.059\n",
      "[10,    12] loss: 0.055\n",
      "[10,    13] loss: 0.057\n",
      "[10,    14] loss: 0.054\n",
      "[10,    15] loss: 0.051\n",
      "[10,    16] loss: 0.048\n",
      "[10,    17] loss: 0.047\n",
      "[10,    18] loss: 0.045\n",
      "[10,    19] loss: 0.044\n",
      "[10,    20] loss: 0.042\n",
      "[10,    21] loss: 0.049\n",
      "[10,    22] loss: 0.047\n",
      "[10,    23] loss: 0.046\n",
      "[10,    24] loss: 0.046\n",
      "[10,    25] loss: 0.046\n",
      "[10,    26] loss: 0.044\n",
      "[10,    27] loss: 0.043\n",
      "[10,    28] loss: 0.042\n",
      "[10,    29] loss: 0.041\n",
      "[10,    30] loss: 0.040\n",
      "[10,    31] loss: 0.038\n",
      "[10,    32] loss: 0.037\n",
      "[10,    33] loss: 0.036\n",
      "[10,    34] loss: 0.043\n",
      "[10,    35] loss: 0.042\n",
      "[10,    36] loss: 0.041\n",
      "[10,    37] loss: 0.048\n",
      "[10,    38] loss: 0.047\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#Defining the convolutional neural network\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Linear(400, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "model  = LeNet5(num_classes=2)\n",
    "learning_rate = 0.001\n",
    "\n",
    "def get_accuracy(pred_arr, original_arr):\n",
    "    pred_arr = pred_arr.detach().numpy()\n",
    "    original_arr = original_arr.numpy()\n",
    "    final_pred= []\n",
    "\n",
    "    for i in range(len(pred_arr)):\n",
    "        final_pred.append(np.argmax(pred_arr[i]))\n",
    "    final_pred = np.array(final_pred)\n",
    "    count = 0\n",
    "\n",
    "    for i in range(len(original_arr)):\n",
    "        if final_pred[i] == original_arr[i]:\n",
    "            count+=1\n",
    "    return count/len(final_pred)*100\n",
    "\n",
    "    \n",
    "\n",
    "#set up the loss function and the optimizer\n",
    "cost = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "train_loss_per_epoch = []\n",
    "\n",
    "#train!\n",
    "\n",
    "#loss function from here: https://neptune.ai/blog/pytorch-loss-functions \n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    epoch_loss_sum = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # forward feed\n",
    "        outputs = model(inputs)\n",
    "        train_acc.append(get_accuracy(outputs, labels))\n",
    "        \n",
    "        #calculate the loss\n",
    "        loss = cost(outputs, labels) #same as cost(output_train, y_train)\n",
    "        epoch_loss_sum += outputs.shape[0] * loss.item()\n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "        # clear out the gradients from the lass step loss.backward() - understand this\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #backward propagation - calculating gradients \n",
    "        loss.backward()\n",
    "        \n",
    "        #updating the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / (i+1):.3f}')       \n",
    "    \n",
    "    train_loss_per_epoch.append(epoch_loss_sum / len(train_dataset))\n",
    "\n",
    "         \n",
    "    # epoch_loss = running_loss / len(train_loader)\n",
    "    # train_loss.append(epoch_loss)\n",
    "\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "PATH = './cifar_net_LeNet5_1.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26627137660980227\n"
     ]
    }
   ],
   "source": [
    "# net = LeNet5(2)\n",
    "# net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "# dataiter = iter(val_loader)\n",
    "# images, labels = next(dataiter)\n",
    "\n",
    "# outputs = net(images)\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# correct = 0\n",
    "# total = 0\n",
    "\n",
    "# y_true = []\n",
    "# y_pred = []\n",
    "\n",
    "\n",
    "# loss = 0\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for data in val_loader:\n",
    "#         images, labels = data\n",
    "#         outputs = net(images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "        \n",
    "#         y_true += labels.tolist()\n",
    "#         y_pred += predicted.tolist()\n",
    "        \n",
    "#         loss += cost(outputs, labels)\n",
    "#     validation_loss = loss.item() / len(val_loader)\n",
    "\n",
    "        \n",
    "# confusion_mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# print('Accuracy on validation set: %d %%' % (100 * correct / total))\n",
    "# print(confusion_mat)\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "# # Create a heatmap of the confusion matrix\n",
    "# sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "# # Set the axis labels\n",
    "# plt.xlabel('Predicted T1 transition')\n",
    "# plt.ylabel('True T1 transition')\n",
    "\n",
    "# Show the plot\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LeNet5(2)\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "dataiter = iter(val_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "outputs = net(images)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "validation_losses = []\n",
    "val_loss_per_epoch = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        epoch_loss_sum = 0.0\n",
    "        val_loss_sum_epoch = 0.0\n",
    "            \n",
    "        for i, data in enumerate(val_loader, 0):\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            y_true += labels.tolist()\n",
    "            y_pred += predicted.tolist()\n",
    "            \n",
    "            running_loss += cost(outputs, labels)\n",
    "            val_loss_sum_epoch += outputs.shape[0] * loss.item()\n",
    "            # print(running_loss)\n",
    "            \n",
    "        validation_loss = running_loss.item() / len(val_loader)\n",
    "        validation_losses.append(validation_loss)\n",
    "        val_loss_per_epoch.append(val_loss_sum_epoch / len(val_dataset))\n",
    "\n",
    "        \n",
    "\n",
    "# confusion_mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# print('Accuracy on validation set: %d %%' % (100 * correct / total))\n",
    "# print(confusion_mat)\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "# # Create a heatmap of the confusion matrix\n",
    "# sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "# # Set the axis labels\n",
    "# plt.xlabel('Predicted T1 transition')\n",
    "# plt.ylabel('True T1 transition')\n",
    "\n",
    "# Show the plot\n",
    "# plt.show()\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_per_epoch)\n",
    "plt.plot(val_loss_per_epoch)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on a test set: 45 %\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAFzCAYAAAAkIOMNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAh+klEQVR4nO3debQcZZnH8e+TAIGwRWTTJE5AArLMDCBLwAFBlE0kgBsoAqJEIIjIDGLUAXUAOYg4RkY07CiCIKAMoiCL4hbCDiGAZAQlAQQM+57wzB9dCZ2Qe28nN923q+r74dRJ37equ57OOSG/PO9bVZGZSJIkldGggS5AkiRpcRlkJElSaRlkJElSaRlkJElSaRlkJElSaRlkJElSaS010AX05KXZeF24NADetPlhA12CVFsv3nZqdPJ8y21yWL/+ru10vQvTtUFGkiS1WZR/Yqb830CSJC2eiP5tfX58jIyI6yNiWkTcHRGfK8a/GRH3RsSdEXFZRAxres+EiJgeEfdFxE59ncMgI0lSXcWg/m19mw38e2ZuAIwBxkfEBsCvgY0y81+APwMTAIp9ewMbAjsD34uIwb2dwCAjSZLaIjMfycxbi9fPAvcAwzPz6sycXRw2GRhRvB4LXJiZL2fmA8B0YIvezmGQkSSprto8tTT/qWIUsAlw4wK7DgR+WbweDjzUtG9GMdYjF/tKklRX/VzsGxHjgHFNQ5Myc9JCjlsBuAQ4IjOfaRr/Mo3pp/MXtwaDjCRJdbWIXZUFFaHlDcFl/lPE0jRCzPmZeWnT+AHAbsAOmTn3MvCZwMimt48oxnrk1JIkSWqLiAjgTOCezDylaXxn4AvA7pn5QtNbLgf2joghEbEWMBqY0ts57MhIklRX7b+PzLuATwB3RcTtxdiXgInAEODXjazD5Mw8ODPvjoiLgGk0ppzGZ+ac3k5gkJEkqa76ObXUl8z8PbCwk1zZy3uOB45v9RwGGUmS6qoCd/Y1yEiSVFdt7sh0QvmjmCRJqi07MpIk1ZVTS5IkqbQqMLVkkJEkqa7syEiSpNKqQJAp/zeQJEm1ZUdGkqS6GuQaGUmSVFYVmFoyyEiSVFcVuGqp/FFMkiTVlh0ZSZLqyqklSZJUWhWYWjLISJJUV3ZkJElSaVWgI1P+KCZJkmrLjowkSXXl1JIkSSqtCkwtGWQkSaorOzKSJKm0KtCRKX8UkyRJtWVHRpKkunJqSZIklZZBRpIklZZrZCRJkgaOHRlJkurKqSVJklRaFZhaMshIklRXdmQkSVJpVaAjU/4oJkmSasuOjCRJNRUV6MgYZCRJqimDjCRJKq/y5xjXyEiSpPKyIyNJUk05tSRJkkrLICNJkkrLICNJkkqrCkHGxb6SJKm07MhIklRX5W/IGGQkSaqrKkwtGWQkSaopg4wkSSqtKgQZF/tKkqTSsiMjSVJNVaEjY5CRJKmuyp9jDDKSJNVVFToyrpGRJEmlZUdGkqSaqkJHxiAjSVJNGWQkSVJ5lT/HuEZGkqS6ioh+bS18/siIuD4ipkXE3RHxuWJ8lYj4dUTcX/z6pmI8ImJiREyPiDsjYtO+zmGQkSRJ7TIb+PfM3AAYA4yPiA2ALwLXZuZo4NriZ4BdgNHFNg44ra8TGGQkSaqpdndkMvORzLy1eP0scA8wHBgLnFscdi6wR/F6LHBeNkwGhkXEW3o7h0FGkqSa6m+QiYhxEXFz0zaul3ONAjYBbgTWyMxHil2PAmsUr4cDDzW9bUYx1iMX+0qSVFP9vWopMycBk1o4zwrAJcARmflM83kzMyMiF7cGOzKSJNVV9HNr5RQRS9MIMedn5qXF8N/nThkVvz5WjM8ERja9fUQx1iODjCRJaototF7OBO7JzFOadl0O7F+83h/4edP4fsXVS2OAp5umoBbKqSVJkmqqAzfEexfwCeCuiLi9GPsScCJwUUR8Cvgr8JFi35XArsB04AXgk32dwCAjSVJNtTvIZObv6XkSaoeFHJ/A+EU5h0FGkqSaqsIjClwjI0mSSsuOjCRJdVX+hoxBRpKkuqrC1JJBRpKkmqpCkHGNjBbZMV+ZwHbbbMVeY3ebN3b1Vb9kz93fz8YbvYO7p971hvc88vDDjNlsE849+8xOlipVyog1hvGrSYdz6yVf5paffpnx+2wHwAlH7MHtl36FKT+ZwE++dRArr7AcAO/Z8h384fwvcNNFX+IP53+Bd2++7gBWr27U7mctdYJBRots7B57cdoPzphvbJ111uXb3/ku79xs84W+5+STTuTfttmmE+VJlTV7zmt88ZRL2fSDx/Pu/U7mMx/dlnesvSbXTr6Xd374BLb46De4/6+PcdSBOwLwj6ee40NH/IDNP3ICBx3zQ846br8B/gbSkufUkhbZOzfbnJkzZ8w3tvbb397j8dddew3DRwxnueWGtrs0qdIefeIZHn3iGQCee+Fl7n3gUd662jCunXzvvGOm3PUAe753EwDuuO/1P6fT/u8Rlh2yNMssvRSvvDq7s4Wra3VLV6U/2taRiYh3RMTRETGx2I6OiPXbdT51pxeef56zzzydgw85bKBLkSrlbW9ZhY3XG8FNUx+cb3y/sVtx1R+mveH4Pd+7Mbff+5AhRvPrwLOW2q0tQSYijgYupPE1pxRbABdExBd7ed+8x4GfeXqfD9NUCZz2vVPZd7/9Gbr88gNdilQZyy+3DBec/GmOOvkSnn3+pXnjX/jUTsyZ8xoXXnnTfMevv/aaHHf4WA477sJOl6ouV4U1Mu2aWvoUsGFmvto8GBGnAHfTeMbCGzQ/Dvyl2Sz2I73VPe668w6uufoq/vtbJ/Pss88QMYhllhnCPh/fd6BLk0ppqaUGccHJB/GTX97Mz6+7Y974vh/Ykl233YhdPjNxvuOHrz6Mn5wyjk//5w95YMYTnS5XXa5bwkh/tCvIvAa8lcaDoJq9pdinmjjnhz+e9/q0//kuQ4cONcRI/fD9Yz/OfQ88ysQfXTdv7H1br8+RB7yXHT/9HV586fV/P668wnJc+t2D+c+JP+dPd/xlIMqV2q5dQeYI4NqIuB94qBh7G7AO4GKJkjv6P47k5pum8NRTT/K+92zLIeM/y8orD+PEE/6LJ2fN4rBDP8N6663P90/3UmtpSdp647X5+G5bctefZzL5wsYs/bGnXs63jvowQ5ZZiitOa/zvdcpdD3L48Rdy8N7b8vaRqzFh3C5MGLcLAB845FQef/K5AfsO6i4VaMgQjQdNtuGDIwYBWwDDi6GZwE2ZOaeV9zu1JA2MN23uvzWkgfLibad2NFqMPupX/fq79v5v7jzgUahtl19n5mvA5HZ9viRJ6p8qdGS8IZ4kSSotb4gnSVJNedWSJEkqrQrkGIOMJEl1NWhQ+ZOMQUaSpJqqQkfGxb6SJKm07MhIklRTLvaVJEmlVYEcY5CRJKmu7MhIkqTSqkKQcbGvJEkqLTsykiTVVAUaMgYZSZLqqgpTSwYZSZJqqgI5xjUykiSpvOzISJJUU04tSZKk0qpAjjHISJJUV3ZkJElSaVUgx7jYV5IklZcdGUmSasqpJUmSVFoVyDEGGUmS6sqOjCRJKq0K5BgX+0qSpPKyIyNJUk05tSRJkkqrAjnGICNJUl1VoSPjGhlJklRadmQkSaqpKnRkDDKSJNVUBXKMQUaSpLqyIyNJkkqrAjnGxb6SJKm8+uzIRMRqwEHAqObjM/PA9pUlSZLarS5TSz8HfgdcA8xpbzmSJKlTKpBjWgoyQzPz6LZXIkmSOmpQm5NMRJwF7AY8lpkbFWMbA98HlgVmA4dm5pRotIe+A+wKvAAckJm39nWOVtbIXBERuy7eV5AkSd0qon9bC84Bdl5g7CTga5m5MXBM8TPALsDoYhsHnNbKCVoJMp+jEWZeiohni+2ZVj5ckiTVV2beAMxacBhYqXi9MvBw8XoscF42TAaGRcRb+jpHn1NLmbli6yVLkqSy6O9i34gYR6N7MtekzJzUx9uOAK6KiJNpNFS2LsaHAw81HTejGHuktw9r6T4yEbE7sG3x428y84pW3idJkrrXoH4ukSlCS1/BZUGHAJ/PzEsi4iPAmcB7F7eGPqeWIuJEGtNL04rtcxHxjcU9oSRJ6g4R0a9tMe0PXFq8vhjYong9ExjZdNyIYqxXrayR2RV4X2aelZln0Vi08/6Wy5UkSXrdw8C7i9fvAe4vXl8O7BcNY4CnM7PXaSVo/REFw3h9sc7KrdcqSZK6VbvvIxMRFwDbAatGxAzgWBo32f1ORCwFvMTra2yupNE8mU7j8utPtnKOVoLMN4DbIuJ6IGislfli619DkiR1o6C9SSYz9+lh1zsXcmwC4xf1HK1ctXRBRPwG2LwYOjozH13UE0mSpO7S38W+3aDHIBMR78jMeyNi02JoRvHrWyPira3cbU+SJHWvqj9r6Uga81bfWsi+pLFAR5IkacD0GGQyc+7im10y86XmfRGxbFurkiRJbVeBhkxLl1//scUxSZJUIoMi+rV1g97WyKxJ49bAy0XEJjBvafNKwNAO1CZJktqoS7JIv/S2RmYn4AAad9Y7pWn8WeBLbaxJkiSpJb2tkTkXODciPpiZl3SwJkmS1AGVvmopIvbNzB8BoyLiyAX3Z+YpC3mbJEkqiQrkmF6nlpYvfl2hE4VIkqTO6pYFu/3R29TSD4pfv9a5ciRJUqeUP8a0cPl1RJwUEStFxNIRcW1EPB4R+3aiOEmSpN60ch+ZHTPzGWA34EFgHeCodhYlSZLaLyL6tXWDVp5+PfeY9wMXZ+bT3VK8JElafJV+aGSTKyLiXuBF4JCIWA14qY/3SJKkLleFxkSfQSYzvxgRJwFPZ+aciHgeGNv+0iRJUjtVIMe01JEBeAeN+8k0H39eG+qRJElqWZ9BJiJ+CLwduB2YUwwnBhlJkkqtFlNLwGbABpmZ7S5GkiR1Tl0W+04F1gQeaXMtkiSpg+rSkVkVmBYRU4CX5w5m5u5tq0qSJKkFrQSZr7a7CEmS1Hnl78e0dvn1bztRiCRJ6qwqPDSylWctjYmImyLiuYh4JSLmRMQznShOkiS1T0T/tm7QytTSqcDewMU0rmDaD1i3nUVJkqT2q8Ji31YeGklmTgcGZ+aczDwb2Lm9ZUmSJPWtlY7MCxGxDHB78aiCR2gxAEmSpO5VgYZMS4HkE8VxhwHPAyOBD7azKEmS1H6DIvq1dYNeOzIRMRg4ITM/TuOJ11/rSFWSJKntuiSL9EuvQaZ42vU/RcQymflKp4qSJEntV4XFvq2skfkL8IeIuJzG1BIAmXlK26qSJElqQStB5v+KbRCwYjHW9gdI/nH6P9p9CkkLsdYuPn1EqosqXLnTSpCZlpkXNw9ExIfbVI8kSeqQKkwttRLGJrQ4JkmSSmRQ9G/rBj12ZCJiF2BXYHhETGzatRIwu92FSZIk9aW3qaWHgZuB3YFbmsafBT7fzqIkSVL7dUtXpT96DDKZeQdwR0T8ODNf7WBNkiSpA6qwRqbPxb6GGEmSqqnSHRlJklRtFWjIVOISckmSVFOLFWQiYtKSLkSSJHVWpR8aGRGr9LSLxmXZkiSpxKowLdPbGpnHgb/SCC5zZfHz6u0sSpIktV+XNFX6pbcg8xdgh8z824I7IuKh9pUkSZI6oVumh/qjt67SfwNv6mHfSUu+FEmSpEXTW0fmluKmeG+Qmd9tUz2SJKlDKtCQ6bUj872OVSFJkjqu0g+NlCRJ1VaFNTK9BZm1I+LynnZm5u5tqEeSJKllfV1+/a1OFSJJkjqrAg2ZXoPMs5n5245VIkmSOqpb1rn0R2+LfR/sVBGSJKnzop//9fn5EWdFxGMRMXWB8c9GxL0RcXdEnNQ0PiEipkfEfRGxUyvfoceOTGbu1coHSJKkcupAR+Yc4FTgvLkDEbE9MBb418x8OSJWL8Y3APYGNgTeClwTEetm5pzeTlCFxyxIkqQulJk3ALMWGD4EODEzXy6OeawYHwtcmJkvZ+YDwHRgi77OYZCRJKmmBug+MusC20TEjRHx24jYvBgfDjQ/AmlGMdb7d+jrgGjYNyKOKX5+W0T0mZAkSVJ3i4j+buMi4uambVwLp10KWAUYAxwFXBSx+NdPtXJDvO8BrwHvAb4OPAtcAmze25skSVJ36+8amcycBExaxLfNAC7NzASmRMRrwKrATGBk03EjirFetTK1tGVmjgdeKop+ElhmEYuWJEldJqJ/22L6GbB94/yxLo1M8QRwObB3RAyJiLWA0cCUvj6slY7MqxExGMjipKvR6NBIkiT1KCIuALYDVo2IGcCxwFnAWcUl2a8A+xfdmbsj4iJgGjAbGN/XFUvQWpCZCFwGrB4RxwMfAr6yGN9HkiR1kXY/aykz9+lh1749HH88cPyinKPPIJOZ50fELcAOQAB7ZOY9i3ISSZLUfapwZ98+g0xEvA14Afjf5rHM/Fs7C5MkSe1V9WctzfULGutjAlgWWAu4j8ad9yRJkgZMK1NL/9z8c0RsChzatookSVJHDGrheUndrpWOzHwy89aI2LIdxUiSpM6pxdRSRBzZ9OMgYFPg4bZVJEmSOqIWi32BFZtez6axZuaS9pQjSZI6pd2XX3dCr0GmuBHeipn5Hx2qR5IkqWU9BpmIWCozZ0fEuzpZkCRJ6owKNGR67chMobEe5vaIuBy4GHh+7s7MvLTNtUmSpDaq/NRSYVngHzSefj33fjIJGGQkSSqxCuSYXoPM6sUVS1N5PcDMlW2tSpIktd2ggS5gCegtyAwGVoCF3i3HICNJkgZcb0Hmkcz8escqkSRJHRUVmFvqLciU/9tJkqQeVeEv+t6CzA4dq0KSJHVcFa5a6nGdT2bO6mQhkiRJi2qRHxopSZKqofz9GIOMJEm1VYGZJYOMJEl1VfWrliRJUoVV4YZ4VfgOkiSppuzISJJUU04tSZKk0ip/jDHISJJUW1XoyLhGRpIklZYdGUmSaqoK3QyDjCRJNVWFqSWDjCRJNVX+GGOQkSSptirQkKnE9JgkSaopOzKSJNXUoApMLhlkJEmqqSpMLRlkJEmqqbAjI0mSyqoKHRkX+0qSpNKyIyNJUk252FeSJJVWFaaWDDKSJNVUFYKMa2QkSVJp2ZGRJKmmvPxakiSV1qDy5xiDjCRJdWVHRpIklZaLfSVJkgaQHRlJkmrKqSVJklRaLvaVJEmlVYWOjGtktMjOm3g8R+23K1//7MffsO+an/2YQ8ZuzXPPPDXf+IP3T2P8nttw6x+u61CVUjUdt9eG/O5L2/Hzz209b2y9NVfgxwdvwc8O34r/+cQmLD9kMABbrbMKF48fw88O34qLx49hy7VXGaiy1aUi+rd1A4OMFtlWO+zKZ4/99hvGZz3+d6bdNoVVVltjvvHX5szhsnO/x/qbbNGpEqXKuuzWhxl3zi3zjX19rw055ar72WPin7h22t85cJtRADz1/Kscet5t7DHxT0z46VRO/PBGA1Cx1F4GGS2y0RtuwvIrrPSG8Z+e+R32OmD8G2L69b/4KZtstT0rrvymTpUoVdYtDz7J0y+8Ot/YqFWHcvMDTwLwx+n/YMeNGv+YuOeRZ3n82ZcBmP7351h26cEsPbhL/hmtrhD93LqBQUZLxB033sCwN6/GiLVGzzf+1D8e547Jv2XbXfYcoMqk6pv+9+fZYf3VANhpozVZc+Vl33DMjhutwbSHn+HVOdnp8tTFBkX0a+sGHQ8yEfHJXvaNi4ibI+LmKy46t5NlqR9eefklfnXxeXzgYwe9Yd/FZ/w3e+x/KIMGmZmldvnKpVPZe8xILh4/huWHDObVOa/Nt3+d1ZfnyJ1G89WfTRugCtWt2t2RiYizIuKxiJi6kH3/HhEZEasWP0dETIyI6RFxZ0Rs2sp3GIirlr4GnL2wHZk5CZgEcN29//CfDSXx+CMzeeKxhznuiP0AeOqJxznh85/k6JPP4K/T7+XMk48B4PlnnmbqLX9k0ODBbDzm3QNZslQpDzz+AgedfSsA//TmoWy73mrz9q2x0hAm7rsxEy6eykOzXhyoElVf5wCnAuc1D0bESGBH4G9Nw7sAo4ttS+C04tdetSXIRMSdPe0C1uhhn0pq+Ki3883zrpz385cP2osJ3zqLFVYaxnGnXzJv/NzvHMc/b7a1IUZawlZZfhlmPf8KEXDw9mtz0ZSHAFhx2aU4bf9NOeWq+7ntb08NbJHqTm2eHcrMGyJi1EJ2fRv4AvDzprGxwHmZmcDkiBgWEW/JzEd6O0e7OjJrADsBTy4wHsAf23ROdciZJx/Dn6fexnPPPMWEA8ey2z6f5l3v+8BAlyXVwjc/+s9ssdYqDFt+aa47eltOveb/GDpkMB8bMxKAX9/9GJfe8jAAH9tqJG9781AO3X5tDt1+bQA+ffatzHr+lQGrX92lv/eRiYhxwLimoUnF7Epv7xkLzMzMO2L+dTbDgYeafp5RjPUaZKIRfJasiDgTODszf7+QfT/OzI/19RlOLUkD47Dzbun7IEltMe2EHTu6gnbKX57u19+1W6y9cp/1Fh2ZKzJzo4gYClwP7JiZT0fEg8BmmflERFwBnDg3O0TEtcDRmXlzb5/flo5MZn6ql319hhhJktR+A3Dd0duBtYC53ZgRwK0RsQUwExjZdOyIYqxXXkoiSZI6IjPvyszVM3NUZo6iMX20aWY+ClwO7FdcvTQGeLqv9TFgkJEkqb7afP11RFwA/AlYLyJmRESPMzbAlcBfgOnA6cChrXwFHxopSVJNtfuhkZm5Tx/7RzW9TmD8op7DICNJUk11yc15+8UgI0lSTVUgx7hGRpIklZcdGUmS6qoCLRmDjCRJNdXuxb6dYJCRJKmmqrDY1zUykiSptOzISJJUUxVoyBhkJEmqrQokGYOMJEk15WJfSZJUWi72lSRJGkB2ZCRJqqkKNGQMMpIk1VYFkoxBRpKkmnKxryRJKi0X+0qSJA0gOzKSJNVUBRoyBhlJkmqrAknGICNJUk1VYbGva2QkSVJp2ZGRJKmmqnDVkkFGkqSaqkCOMchIklRbFUgyBhlJkmrKxb6SJEkDyI6MJEk15WJfSZJUWhXIMQYZSZJqqwJJxiAjSVJNudhXkiRpANmRkSSpplzsK0mSSqsCOcYgI0lSbVUgybhGRpIklZYdGUmSaqoKVy0ZZCRJqikX+0qSpNKqQI4xyEiSVFdV6Mi42FeSJJWWHRlJkmqr/C0Zg4wkSTVVhaklg4wkSTVVgRxjkJEkqa6q0JFxsa8kSSotOzKSJNWUd/aVJEnlVf4cY5CRJKmuKpBjXCMjSZLKy46MJEk1VYWrlgwykiTVVBUW+zq1JElSXUU/t74+PuKsiHgsIqY2jX0zIu6NiDsj4rKIGNa0b0JETI+I+yJip1a+gkFGkqSaanOOATgH2HmBsV8DG2XmvwB/BiYARMQGwN7AhsV7vhcRg/s6gUFGkiS1RWbeAMxaYOzqzJxd/DgZGFG8HgtcmJkvZ+YDwHRgi77OYZCRJKmmIvq3LQEHAr8sXg8HHmraN6MY65VBRpKkmor+/hcxLiJubtrGtXzuiC8Ds4Hz+/MdvGpJkqSa6m9XJTMnAZMW/bxxALAbsENmZjE8ExjZdNiIYqxXdmQkSVLHRMTOwBeA3TPzhaZdlwN7R8SQiFgLGA1M6evz7MhIkqS2iIgLgO2AVSNiBnAsjauUhgC/jkZLaHJmHpyZd0fERcA0GlNO4zNzTl/nMMhIklRT7b6zb2bus5DhM3s5/njg+EU5h0FGkqSaqsKdfQ0ykiTVVBWeteRiX0mSVFp2ZCRJqqkKNGQMMpIk1VYFkoxBRpKkmnKxryRJKi0X+0qSJA0gOzKSJNVUBRoyBhlJkmqrAknGICNJUk1VYbGva2QkSVJp2ZGRJKmmqnDVUmTmQNegCoqIcZk5aaDrkOrGP3uqG6eW1C7jBroAqab8s6daMchIkqTSMshIkqTSMsioXZyjlwaGf/ZUKy72lSRJpWVHRpIklZZBRktUROwcEfdFxPSI+OJA1yPVRUScFRGPRcTUga5F6iSDjJaYiBgM/A+wC7ABsE9EbDCwVUm1cQ6w80AXIXWaQUZL0hbA9Mz8S2a+AlwIjB3gmqRayMwbgFkDXYfUaQYZLUnDgYeafp5RjEmS1BYGGUmSVFoGGS1JM4GRTT+PKMYkSWoLg4yWpJuA0RGxVkQsA+wNXD7ANUmSKswgoyUmM2cDhwFXAfcAF2Xm3QNblVQPEXEB8CdgvYiYERGfGuiapE7wzr6SJKm07MhIkqTSMshIkqTSMshIkqTSMshIkqTSMshIkqTSMshIiyEi5kTE7RExNSIujoih/fiscyLiQ8XrM3p70GZEbBcRWy/GOR6MiFUXGLux+A5/i4jHi9e3R8SoiDg+Ih6KiOeWdC2LUfvXI+K9xesjmn+vI+LKiBjW7hokdS+DjLR4XszMjTNzI+AV4ODmnRGx1OJ8aGZ+OjOn9XLIdsASCQ+ZuWVmbgwcA/yk+D4bZ+aDwP/SeAhob3qsZXG/fw91HpOZ1xQ/HgEMbdq3a2Y+taTOJal8DDJS//0OWKfoUPwuIi4HpkXE4Ij4ZkTcFBF3RsRnAKLh1Ii4LyKuAVaf+0ER8ZuI2Kx4vXNE3BoRd0TEtRExikZg+nzROdkmIlaLiEuKc9wUEe8q3vvmiLg6Iu6OiDOAWJQvlJmTM/ORnvb3UMs5EfH9iLgROCkitoiIP0XEbRHxx4hYr3jvARFxaUT8KiLuj4iTivHBxWdMjYi7IuLzxfg5EfGhiDgceCtwfURcX+yb12mKiCOL906NiCPm1hkR90TE6cXvxdURsdyi/F5I6m5L7F9NUh0VnYddgF8VQ5sCG2XmAxExDng6MzePiCHAHyLiamATYD1gA2ANYBpw1gKfuxpwOrBt8VmrZOasiPg+8Fxmnlwc92Pg25n5+4h4G427Kq8PHAv8PjO/HhHvB5boXV4z88GF1PIpGs/X2joz50TESsA2mTm7mBo6Afhg8REbF78PLwP3RcR3aQS64UWXiwWnjDJzYkQcCWyfmU8s8Pv1TuCTwJY0QtuNEfFb4ElgNLBPZh4UERcVNfxoSf5+SBo4Bhlp8SwXEbcXr38HnEljmmVKZj5QjO8I/Mvc9S/AyjT+Ut0WuCAz5wAPR8R1C/n8McANcz8rM2f1UMd7gQ0i5jVcVoqIFYpz7FW89xcR8eTifc1FdnHxvaDxfc+NiNFAAks3HXdtZj4NEBHTgH8C7gbWLkLNL4CrF+G8/wZclpnPF595KbANjWd9PZCZtxfH3QKMWozvJalLGWSkxfNisb5kniJMPN88BHw2M69a4Lhdl2Adg4AxmfnSQmoZCM3f/7+A6zNzz2Iq6jdN+15uej0HWCozn4yIfwV2ojFt9RHgwCVQ04LncmpJqhDXyEjtcxVwSEQsDRAR60bE8sANwEeLNSFvAbZfyHsnA9tGxFrFe1cpxp8FVmw67mrgs3N/iIiNi5c3AB8rxnYB3rSkvlSTBWtZ0MrAzOL1AX19WLHWZVBmXgJ8hcY0Xavn/B2wR0QMLX6P9yzGJFWcQUZqnzNorH+5NSKmAj+g0QW9DLi/2HcejScWzyczHwfGAZdGxB3AT4pd/wvsOXeBLXA4sFmxmHgar1899TUaQehuGlNMf1uUwiPipIiYAQyNxpOUv7qQwxasZUEnAd+IiNtorfs7HPhNMWX3I2DCQo6ZBPxq7mLfuTLzVuAcYApwI3BGZt7WwjkllZxPv5YkSaVlR0aSJJWWQUaSJJWWQUaSJJWWQUaSJJWWQUaSJJWWQUaSJJWWQUaSJJWWQUaSJJXW/wOlIIaowxM/mQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define an empty list to store loss values\n",
    "model.eval()\n",
    "\n",
    "\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        y_true += labels.tolist()\n",
    "        y_pred += predicted.tolist()\n",
    "        \n",
    "confusion_mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print('Accuracy on a test set: %d %%' % (100 * correct / total))\n",
    "# print(confusion_mat)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# # Create a heatmap of the confusion matrix\n",
    "sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "# # Set the axis labels\n",
    "plt.xlabel('Predicted T1 transition')\n",
    "plt.ylabel('True T1 transition')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
